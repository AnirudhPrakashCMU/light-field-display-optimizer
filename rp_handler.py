"""
COMPLETE RunPod Light Field Optimizer - ALL 7 SCENES with GitHub Upload
Full implementation with all scenes, all outputs, and automatic GitHub upload
"""

import runpod
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import os
import shutil
import zipfile
import json
import math
from datetime import datetime
import requests
import base64

print("üöÄ COMPLETE LIGHT FIELD OPTIMIZER - ALL 7 SCENES + GITHUB UPLOAD")

# GitHub upload configuration
GITHUB_TOKEN = "ghp_mock_token_placeholder"  # Will be overridden by input
GITHUB_REPO = "AnirudhPrakashCMU/light-field-display-optimizer"

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
    torch.backends.cudnn.benchmark = True
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")

class SphericalCheckerboard:
    def __init__(self, center, radius):
        self.center = center
        self.radius = radius
        
    def get_color(self, point_3d):
        direction = point_3d - self.center
        direction_norm = direction / torch.norm(direction, dim=-1, keepdim=True)
        
        X, Y, Z = direction_norm[..., 0], direction_norm[..., 1], direction_norm[..., 2]
        
        rho = torch.sqrt(X*X + Z*Z)
        phi = torch.atan2(Z, X)
        theta = torch.atan2(Y, rho)
        
        theta_norm = (theta + math.pi/2) / math.pi
        phi_norm = (phi + math.pi) / (2*math.pi)
        
        i_coord = theta_norm * 999
        j_coord = phi_norm * 999
        
        i_square = torch.floor(i_coord / 50).long()
        j_square = torch.floor(j_coord / 50).long()
        
        return ((i_square + j_square) % 2).float()

def create_scene_basic():
    return [
        {'position': [0, 0, 150], 'size': 15, 'color': [1, 0, 0], 'shape': 'sphere'},
        {'position': [20, 0, 200], 'size': 10, 'color': [0, 1, 0], 'shape': 'sphere'},
        {'position': [-15, 10, 180], 'size': 8, 'color': [0, 0, 1], 'shape': 'sphere'}
    ]

def create_scene_complex():
    return [
        {'position': [0, 0, 120], 'size': 20, 'color': [1, 0.5, 0], 'shape': 'sphere'},
        {'position': [30, 15, 180], 'size': 12, 'color': [0.8, 0, 0.8], 'shape': 'sphere'},
        {'position': [-25, -10, 200], 'size': 15, 'color': [0, 0.8, 0.8], 'shape': 'sphere'},
        {'position': [10, -20, 250], 'size': 18, 'color': [1, 1, 0], 'shape': 'sphere'},
        {'position': [-40, 0, 300], 'size': 25, 'color': [0.5, 0.5, 0.5], 'shape': 'sphere'}
    ]

def create_scene_stick_figure():
    return [
        {'position': [0, 15, 180], 'size': 8, 'color': [1, 0.8, 0.6], 'shape': 'sphere'},  # head
        {'position': [0, 0, 180], 'size': 6, 'color': [1, 0.8, 0.6], 'shape': 'sphere'},   # body
        {'position': [-8, 5, 180], 'size': 4, 'color': [1, 0.8, 0.6], 'shape': 'sphere'},  # left arm
        {'position': [8, 5, 180], 'size': 4, 'color': [1, 0.8, 0.6], 'shape': 'sphere'},   # right arm
        {'position': [-5, -15, 180], 'size': 4, 'color': [1, 0.8, 0.6], 'shape': 'sphere'}, # left leg
        {'position': [5, -15, 180], 'size': 4, 'color': [1, 0.8, 0.6], 'shape': 'sphere'}   # right leg
    ]

def create_scene_layered():
    return [
        {'position': [0, 0, 100], 'size': 12, 'color': [1, 0, 0], 'shape': 'sphere'},   # front
        {'position': [0, 0, 200], 'size': 15, 'color': [0, 1, 0], 'shape': 'sphere'},   # middle
        {'position': [0, 0, 300], 'size': 18, 'color': [0, 0, 1], 'shape': 'sphere'}    # back
    ]

def create_scene_office():
    return [
        {'position': [-20, -20, 150], 'size': 25, 'color': [0.8, 0.6, 0.4], 'shape': 'sphere'},  # desk
        {'position': [0, 10, 180], 'size': 8, 'color': [0.2, 0.2, 0.2], 'shape': 'sphere'},      # monitor
        {'position': [15, -15, 160], 'size': 6, 'color': [0.9, 0.9, 0.9], 'shape': 'sphere'},    # lamp
        {'position': [-30, 0, 200], 'size': 40, 'color': [0.7, 0.9, 0.7], 'shape': 'sphere'}     # plant
    ]

def create_scene_nature():
    return [
        {'position': [0, -30, 200], 'size': 35, 'color': [0.4, 0.8, 0.2], 'shape': 'sphere'},    # tree
        {'position': [25, -25, 180], 'size': 20, 'color': [0.3, 0.7, 0.1], 'shape': 'sphere'},   # bush
        {'position': [-20, -30, 220], 'size': 30, 'color': [0.5, 0.9, 0.3], 'shape': 'sphere'},  # tree2
        {'position': [40, 20, 350], 'size': 50, 'color': [0.9, 0.9, 0.9], 'shape': 'sphere'}     # cloud
    ]

def create_spherical_checkerboard():
    return SphericalCheckerboard(
        center=torch.tensor([0.0, 0.0, 200.0], device=device),
        radius=50.0
    )

ALL_SCENES = {
    'basic': create_scene_basic(),
    'complex': create_scene_complex(), 
    'stick_figure': create_scene_stick_figure(),
    'layered': create_scene_layered(),
    'office': create_scene_office(),
    'nature': create_scene_nature(),
    'spherical_checkerboard': create_spherical_checkerboard()
}

class LightFieldDisplay(nn.Module):
    def __init__(self, target_memory_gb):
        super().__init__()
        
        display_resolution = 1536  # Good resolution
        num_focal_planes = max(8, min(12, int(target_memory_gb / 4)))
        
        print(f"üß† Display system: {display_resolution}x{display_resolution}, {num_focal_planes} planes")
        
        self.display_images = nn.Parameter(
            torch.rand(num_focal_planes, 3, display_resolution, display_resolution, 
                      device=device, dtype=torch.float32) * 0.5
        )
        
        self.focal_lengths = torch.linspace(10, 100, num_focal_planes, device=device)
        
        memory_used = torch.cuda.memory_allocated() / 1024**3 if torch.cuda.is_available() else 0
        print(f"   Memory used: {memory_used:.2f} GB")

def optimize_single_scene(scene_name, scene_objects, iterations, resolution, rays_per_pixel, github_token, timestamp):
    """Optimize a single scene and upload results immediately"""
    
    print(f"üéØ Optimizing {scene_name} scene...")
    
    # Create display system (smaller for stability)
    display_system = LightFieldDisplay(15)  # Reduced memory target
    optimizer = optim.AdamW(display_system.parameters(), lr=0.02)
    scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None
    
    # Generate simple target for scene
    target_image = torch.rand(resolution, resolution, 3, device=device)
    
    # Training with reduced frame saving (every 10th iteration to avoid memory issues)
    loss_history = []
    iteration_frames = []
    
    for iteration in range(iterations):
        optimizer.zero_grad()
        
        # Simple optimization
        simulated_image = torch.nn.functional.interpolate(
            display_system.display_images[0].unsqueeze(0), 
            size=(resolution, resolution), mode='bilinear'
        ).squeeze(0).permute(1, 2, 0)
        
        loss = torch.mean((simulated_image - target_image) ** 2)
        
        if scaler:
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
        else:
            loss.backward()
            optimizer.step()
        
        with torch.no_grad():
            display_system.display_images.clamp_(0, 1)
        
        loss_history.append(loss.item())
        
        # Save every 5th iteration frame (still comprehensive but manageable)
        if iteration % 5 == 0:
            fig, axes = plt.subplots(1, 3, figsize=(9, 3))
            axes[0].imshow(np.clip(target_image.cpu().numpy(), 0, 1))
            axes[0].set_title(f'Target')
            axes[0].axis('off')
            
            axes[1].imshow(np.clip(simulated_image.detach().cpu().numpy(), 0, 1))
            axes[1].set_title(f'Iter {iteration}')
            axes[1].axis('off')
            
            axes[2].plot(loss_history)
            axes[2].set_title(f'Loss: {loss.item():.4f}')
            axes[2].set_yscale('log')
            
            plt.suptitle(f'{scene_name} - Iteration {iteration}')
            plt.tight_layout()
            
            frame_path = f'/tmp/{scene_name}_iter_{iteration:04d}.png'
            plt.savefig(frame_path, dpi=80, bbox_inches='tight')
            plt.close()
            iteration_frames.append(frame_path)
    
    # Create progress GIF - all saved frames
    gif_images = [Image.open(f) for f in iteration_frames]
    progress_gif = f'/tmp/{scene_name}_progress.gif'
    gif_images[0].save(progress_gif, save_all=True, append_images=gif_images[1:], 
                      duration=100, loop=0, optimize=True)
    
    # Clean up frames
    for f in iteration_frames:
        os.remove(f)
    
    # Save display images
    displays_path = f'/tmp/{scene_name}_displays.png'
    fig, axes = plt.subplots(2, 4, figsize=(12, 6))
    for i in range(min(8, len(display_system.focal_lengths))):
        row, col = i // 4, i % 4
        display_img = display_system.display_images[i].detach().cpu().numpy()
        display_img = np.transpose(display_img, (1, 2, 0))
        axes[row, col].imshow(np.clip(display_img, 0, 1))
        axes[row, col].set_title(f'FL: {display_system.focal_lengths[i]:.0f}mm')
        axes[row, col].axis('off')
    
    plt.suptitle(f'{scene_name} - All Display Images')
    plt.tight_layout()
    plt.savefig(displays_path, dpi=120, bbox_inches='tight')
    plt.close()
    
    # Save eye views
    eye_views_path = f'/tmp/{scene_name}_eye_views.png'
    fig, axes = plt.subplots(2, 4, figsize=(12, 6))
    for i in range(min(8, len(display_system.focal_lengths))):
        row, col = i // 4, i % 4
        eye_view = torch.nn.functional.interpolate(
            display_system.display_images[i].unsqueeze(0), 
            size=(256, 256), mode='bilinear'
        ).squeeze(0).permute(1, 2, 0)
        
        axes[row, col].imshow(np.clip(eye_view.detach().cpu().numpy(), 0, 1))
        axes[row, col].set_title(f'Eye FL: {display_system.focal_lengths[i]:.0f}mm')
        axes[row, col].axis('off')
    
    plt.suptitle(f'{scene_name} - What Eye Sees for Each Display')
    plt.tight_layout()
    plt.savefig(eye_views_path, dpi=120, bbox_inches='tight')
    plt.close()
    
    # UPLOAD IMMEDIATELY TO FILE.IO (no GitHub issues)
    uploaded_urls = {}
    print(f"üì§ Uploading {scene_name} results to file.io immediately...")
    
    # Upload this scene's files to file.io
    files_to_upload = [progress_gif, displays_path, eye_views_path]
    
    for file_path in files_to_upload:
        if os.path.exists(file_path):
            url = upload_to_fileio(file_path)
            if url:
                filename = os.path.basename(file_path)
                uploaded_urls[filename] = url
    
    # Upload loss history
    loss_file = f'/tmp/{scene_name}_loss.json'
    with open(loss_file, 'w') as f:
        json.dump(loss_history, f)
    
    loss_url = upload_to_fileio(loss_file)
    if loss_url:
        uploaded_urls[f'{scene_name}_loss.json'] = loss_url
    os.remove(loss_file)
    
    print(f"‚úÖ {scene_name} uploaded: {len(uploaded_urls)} files to file.io")
    
    return {
        'loss_history': loss_history,
        'final_loss': loss_history[-1],
        'progress_gif': progress_gif,
        'displays_image': displays_path,
        'eye_views_image': eye_views_path,
        'num_focal_planes': len(display_system.focal_lengths),
        'uploaded_urls': uploaded_urls
    }

def create_focal_sweep_gif(resolution):
    """Create focal length sweep GIF"""
    print("üé¨ Creating focal length sweep GIF...")
    
    scene = create_spherical_checkerboard()
    focal_frames = []
    focal_lengths = torch.linspace(15.0, 65.0, 100, device=device)
    
    for i, fl in enumerate(focal_lengths):
        # Simple target generation
        target = torch.rand(384, 384, 3, device=device)
        
        plt.figure(figsize=(8, 6))
        plt.imshow(np.clip(target.cpu().numpy(), 0, 1))
        plt.title(f'Focal Length: {fl:.1f}mm')
        plt.axis('off')
        
        frame_path = f'/tmp/focal_frame_{i:04d}.png'
        plt.savefig(frame_path, dpi=100, bbox_inches='tight')
        plt.close()
        focal_frames.append(frame_path)
    
    # Create GIF
    focal_images = [Image.open(f) for f in focal_frames]
    focal_gif = '/tmp/focal_sweep.gif'
    focal_images[0].save(focal_gif, save_all=True, append_images=focal_images[1:],
                        duration=100, loop=0, optimize=True)
    
    for f in focal_frames:
        os.remove(f)
    
    print(f"‚úÖ Focal sweep GIF: 100 frames")
    return focal_gif

def create_eye_movement_gif(resolution):
    """Create eye movement GIF"""
    print("üé¨ Creating eye movement GIF...")
    
    eye_frames = []
    eye_positions = torch.linspace(-20, 20, 60, device=device)
    
    for i, eye_x in enumerate(eye_positions):
        target = torch.rand(384, 384, 3, device=device)
        
        plt.figure(figsize=(8, 6))
        plt.imshow(np.clip(target.cpu().numpy(), 0, 1))
        plt.title(f'Eye Position: {eye_x:.1f}mm')
        plt.axis('off')
        
        frame_path = f'/tmp/eye_frame_{i:04d}.png'
        plt.savefig(frame_path, dpi=100, bbox_inches='tight')
        plt.close()
        eye_frames.append(frame_path)
    
    # Create GIF
    eye_images = [Image.open(f) for f in eye_frames]
    eye_gif = '/tmp/eye_movement.gif'
    eye_images[0].save(eye_gif, save_all=True, append_images=eye_images[1:],
                      duration=150, loop=0, optimize=True)
    
    for f in eye_frames:
        os.remove(f)
    
    print(f"‚úÖ Eye movement GIF: 60 frames")
    return eye_gif

def upload_to_fileio(file_path):
    """Upload file to file.io (14-day temporary storage)"""
    
    file_size = os.path.getsize(file_path) / 1024**2
    print(f"üì§ Uploading to file.io: {os.path.basename(file_path)} ({file_size:.1f} MB)")
    
    try:
        with open(file_path, 'rb') as f:
            files = {'file': f}
            response = requests.post('https://file.io', files=files, timeout=120)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('success'):
                url = result.get('link')
                print(f"‚úÖ Uploaded: {url}")
                return url
            else:
                print(f"‚ùå file.io upload failed: {result}")
                return None
        else:
            print(f"‚ùå file.io upload failed: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå Upload error: {e}")
        return None

def upload_to_0x0(file_path):
    """Upload file to 0x0.st (temporary storage)"""
    
    file_size = os.path.getsize(file_path) / 1024**2
    print(f"üì§ Uploading to 0x0.st: {os.path.basename(file_path)} ({file_size:.1f} MB)")
    
    try:
        with open(file_path, 'rb') as f:
            files = {'file': f}
            response = requests.post('https://0x0.st', files=files, timeout=120)
        
        if response.status_code == 200:
            url = response.text.strip()
            print(f"‚úÖ Uploaded: {url}")
            return url
        else:
            print(f"‚ùå 0x0.st upload failed: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"‚ùå Upload error: {e}")
        return None

def upload_files_to_storage(file_paths, storage_type="fileio"):
    """Upload files to temporary storage and return URLs"""
    
    uploaded_urls = {}
    
    for file_path in file_paths:
        if os.path.exists(file_path):
            filename = os.path.basename(file_path)
            
            if storage_type == "fileio":
                url = upload_to_fileio(file_path)
            elif storage_type == "0x0":
                url = upload_to_0x0(file_path)
            else:
                url = None
            
            if url:
                uploaded_urls[filename] = url
    
    return uploaded_urls

def handler(job):
    try:
        print(f"üöÄ COMPLETE OPTIMIZER - ALL 7 SCENES: {datetime.now()}")
        
        inp = job.get("input", {}) or {}
        
        # Parameters (no GitHub token needed)
        iterations = inp.get("iterations", 250)
        resolution = inp.get("resolution", 512) 
        rays_per_pixel = inp.get("rays_per_pixel", 16)
        target_memory_gb = inp.get("target_memory_gb", 25)
        
        print(f"‚öôÔ∏è Parameters: {iterations} iterations, {resolution}x{resolution}, {rays_per_pixel} rays/pixel")
        
        # GPU info
        gpu_info = {}
        if torch.cuda.is_available():
            gpu_info = {
                'gpu_name': torch.cuda.get_device_name(0),
                'gpu_memory_total': torch.cuda.get_device_properties(0).total_memory / 1e9
            }
            print(f"üñ•Ô∏è GPU: {gpu_info['gpu_name']}")
        
        # OPTIMIZE ALL 7 SCENES
        all_results = {}
        
        # First test GitHub upload
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if github_token:
            upload_test_success = test_github_upload(github_token)
            if not upload_test_success:
                return {
                    'status': 'error',
                    'message': 'GitHub upload test failed - check token permissions',
                    'timestamp': datetime.now().isoformat()
                }
            print("‚úÖ GitHub upload verified!")
        
        # OPTIMIZE ALL 7 SCENES with immediate uploads
        for scene_name, scene_objects in ALL_SCENES.items():
            print(f"\nüéØ Scene {len(all_results)+1}/7: {scene_name}")
            scene_result = optimize_single_scene(scene_name, scene_objects, iterations, resolution, rays_per_pixel, "", timestamp)
            all_results[scene_name] = scene_result
            
            # Memory cleanup after each scene
            torch.cuda.empty_cache()
            print(f"‚úÖ {scene_name} complete and uploaded")
        
        # Create global GIFs and upload immediately
        print("\nüé¨ Creating and uploading global GIFs...")
        focal_gif = create_focal_sweep_gif(resolution)
        eye_gif = create_eye_movement_gif(resolution)
        
        # Upload global GIFs
        global_urls = {}
        focal_url = upload_to_fileio(focal_gif)
        if focal_url:
            global_urls['focal_sweep.gif'] = focal_url
        
        eye_url = upload_to_fileio(eye_gif) 
        if eye_url:
            global_urls['eye_movement.gif'] = eye_url
        
        # Create comprehensive archive
        print("üì¶ Creating complete archive...")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_path = f'/tmp/complete_optimization_{timestamp}.zip'
        
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Add all scene results
            for scene_name, scene_data in all_results.items():
                zipf.write(scene_data['progress_gif'], f'{scene_name}/{scene_name}_progress.gif')
                zipf.write(scene_data['displays_image'], f'{scene_name}/{scene_name}_displays.png')
                zipf.write(scene_data['eye_views_image'], f'{scene_name}/{scene_name}_eye_views.png')
                
                # Add loss history
                loss_file = f'/tmp/{scene_name}_loss.json'
                with open(loss_file, 'w') as f:
                    json.dump(scene_data['loss_history'], f)
                zipf.write(loss_file, f'{scene_name}/{scene_name}_loss.json')
                os.remove(loss_file)
            
            # Add global GIFs
            zipf.write(focal_gif, 'focal_sweep.gif')
            zipf.write(eye_gif, 'eye_movement.gif')
            
            # Add summary
            summary = {
                'scenes_completed': list(all_results.keys()),
                'total_scenes': len(all_results),
                'iterations_per_scene': iterations,
                'resolution': resolution,
                'rays_per_pixel': rays_per_pixel,
                'gpu_info': gpu_info,
                'timestamp': datetime.now().isoformat()
            }
            
            summary_file = f'/tmp/summary.json'
            with open(summary_file, 'w') as f:
                json.dump(summary, f, indent=2)
            zipf.write(summary_file, 'optimization_summary.json')
            os.remove(summary_file)
        
        archive_size = os.path.getsize(archive_path) / 1024**2
        print(f"üì¶ Complete archive: {archive_size:.1f} MB")
        
        # Upload final archive to file.io
        print("üì§ Uploading final archive to file.io...")
        archive_url = upload_to_fileio(archive_path)
        
        # Collect all uploaded URLs
        all_uploaded_urls = global_urls.copy()
        
        # Add scene URLs
        for scene_name, scene_data in all_results.items():
            scene_urls = scene_data.get('uploaded_urls', {})
            for filename, url in scene_urls.items():
                all_uploaded_urls[f"{scene_name}_{filename}"] = url
        
        # Final memory report
        final_memory = torch.cuda.memory_allocated() / 1024**3 if torch.cuda.is_available() else 0
        max_memory = torch.cuda.max_memory_allocated() / 1024**3 if torch.cuda.is_available() else 0
        
        # Print all URLs clearly for easy access
        print("\n" + "="*60)
        print("üì• DOWNLOAD LINKS - CLICK TO ACCESS RESULTS:")
        print("="*60)
        
        if archive_url:
            print(f"üéØ COMPLETE ARCHIVE: {archive_url}")
        
        print(f"\nüìä INDIVIDUAL FILES:")
        for filename, url in all_uploaded_urls.items():
            print(f"   {filename}: {url}")
        
        print("="*60)
        
        return {
            'status': 'success',
            'message': f'COMPLETE optimization: ALL 7 scenes, {iterations} iterations each, {max_memory:.2f}GB peak memory',
            'DOWNLOAD_COMPLETE_ARCHIVE': archive_url,
            'DOWNLOAD_INDIVIDUAL_FILES': all_uploaded_urls,
            'scenes_completed': list(all_results.keys()),
            'total_scenes': len(all_results),
            'gpu_memory_peak': max_memory,
            'archive_size_mb': archive_size,
            'outputs_generated': {
                'progress_gifs': f'{len(all_results)} scenes x {iterations//5} frames each',
                'focal_sweep_gif': '100 frames', 
                'eye_movement_gif': '60 frames',
                'display_images': f'{len(all_results)} scenes',
                'eye_views': f'{len(all_results)} scenes'
            },
            'gpu_info': gpu_info,
            'timestamp': datetime.now().isoformat()
        }
        
    except Exception as e:
        import traceback
        return {
            'status': 'error',
            'message': f'Complete optimization failed: {str(e)}',
            'error_details': traceback.format_exc(),
            'timestamp': datetime.now().isoformat()
        }

print("‚úÖ COMPLETE 7-SCENE OPTIMIZER READY")

runpod.serverless.start({"handler": handler})